\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{elsarticle-num}
\emailauthor{lzh@fudan.edu.cn}{Zhihui Lu\corref {mycorrespondingauthor}}
\citation{Jiang2017Pytheas:Exploration-Exploitation}
\citation{Mao2017NeuralPensieve}
\citation{Li2017}
\citation{JiangVIA:Selection}
\citation{GaoMachineOptimization}
\citation{Edge}
\Newlabel{mymainaddress}{a}
\Newlabel{hismainaddress}{b}
\Newlabel{hisaddress}{c}
\@LN@col{1}
\Newlabel{mycorrespondingauthor}{1}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@LN@col{2}
\citation{Lecun2015}
\citation{Langkvist2014AModeling}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{2}{section.2}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The basic working procedure of CDN}}{2}{figure.1}}
\newlabel{fig:CDN}{{1}{2}{The basic working procedure of CDN}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The structure of cache server groups}}{2}{figure.2}}
\newlabel{fig: the structure of PoP}{{2}{2}{The structure of cache server groups}{figure.2}{}}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{\numberline {3}Problem Formulation and Models Comparison}{3}{section.3}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The feature list}}{3}{table.1}}
\newlabel{feature_list}{{1}{3}{The feature list}{table.1}{}}
\@LN@col{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Linear Models for Sequence Learning}{4}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Non-linear for Sequence Learning}{4}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Feed Forward Neural Network}{4}{subsubsection.3.2.1}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces MLP structure}}{4}{figure.3}}
\newlabel{fig:RNN}{{3}{4}{MLP structure}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Sigmoid function as activation function}}{4}{figure.4}}
\newlabel{fig:sigmoid}{{4}{4}{Sigmoid function as activation function}{figure.4}{}}
\citation{HermansTrainingNetworks}
\citation{Bengio1994LearningDifficult}
\citation{ChoLearningTranslation}
\citation{Bengio1994LearningDifficult}
\citation{Hochreiter1997LongMemory}
\@LN@col{1}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}RNN}{5}{subsubsection.3.2.2}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The left shows the backloop structure of RNN and right shows that RNN can be thought as infinite deep layers neural network unfolded along the dimension of time}}{5}{figure.5}}
\newlabel{fig:RNN can be thought as infinite deep layers neural network along the dimensions of time}{{5}{5}{The left shows the backloop structure of RNN and right shows that RNN can be thought as infinite deep layers neural network unfolded along the dimension of time}{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Models Comparisons}{5}{subsection.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Methods}{5}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Feature Engineering}{5}{subsection.4.1}}
\citation{Ester1996A}
\citation{Hochreiter1997LongMemory}
\citation{MalhotraLongSeries}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Models Comparison}}{6}{table.2}}
\newlabel{models_comparison}{{2}{6}{Models Comparison}{table.2}{}}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces three steps of feature engineering}}{6}{figure.6}}
\newlabel{fig:Correlation_matrix}{{6}{6}{three steps of feature engineering}{figure.6}{}}
\@LN@col{2}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Feature Clustering and Selection}}{6}{algorithm.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Prediction Model Design}{6}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}LSTM}{6}{subsubsection.4.2.1}}
\citation{TensorFlow}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces LSTM cell}}{7}{figure.7}}
\newlabel{fig:LSTMCELL}{{7}{7}{LSTM cell}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces tanh as activation function}}{7}{figure.8}}
\newlabel{fig:tanh}{{8}{7}{tanh as activation function}{figure.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}LSTM auto-encoder}{7}{subsubsection.4.2.2}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces LSTM Auto-encoder Model}}{7}{figure.9}}
\newlabel{fig:RNN_encoder-decoder}{{9}{7}{LSTM Auto-encoder Model}{figure.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Evaluation}{7}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Experimental Settings and Dataset}{7}{subsection.5.1}}
\citation{Krishnan2000}
\citation{Hasan2014}
\citation{Tang2017RethinkingDemands}
\citation{Borst2010}
\citation{Leconte2016}
\citation{Applegate2016}
\citation{Jiang2017Pytheas:Exploration-Exploitation}
\citation{JiangCFA:Optimization}
\citation{Tang2017RethinkingDemands}
\citation{Jiang2017Pytheas:Exploration-Exploitation}
\citation{Mao2017NeuralPensieve}
\citation{Zhao2017LearningNetworks}
\citation{Yadwadkar2017SelectingClouds}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces lstm auto-encoder with a deep feadfoward network}}{8}{figure.10}}
\newlabel{fig:our_models}{{10}{8}{lstm auto-encoder with a deep feadfoward network}{figure.10}{}}
\@LN@col{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Baseline}{8}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Experimental Results}{8}{subsection.5.3}}
\@LN@col{2}
\@writefile{toc}{\contentsline {section}{\numberline {6}Related Work}{8}{section.6}}
\citation{Lecun2015}
\citation{Schmidhuber1989}
\citation{Hochreiter1997LongMemory}
\citation{Qin}
\citation{Zhu2017DeepUber}
\bibstyle{unsrt}
\bibdata{mendeley}
\bibcite{Jiang2017Pytheas:Exploration-Exploitation}{{1}{}{{}}{{}}}
\bibcite{Mao2017NeuralPensieve}{{2}{}{{}}{{}}}
\bibcite{Li2017}{{3}{}{{}}{{}}}
\bibcite{JiangVIA:Selection}{{4}{}{{}}{{}}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Performance Comparison}}{9}{table.3}}
\newlabel{my-label}{{3}{9}{Performance Comparison}{table.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The prediction result on training set.}}{9}{figure.11}}
\newlabel{fig:result_training_set}{{11}{9}{The prediction result on training set}{figure.11}{}}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion and Future Work}{9}{section.7}}
\@LN@col{2}
\@writefile{toc}{\contentsline {section}{\numberline {8}Acknowledgment}{9}{section.8}}
\bibcite{GaoMachineOptimization}{{5}{}{{}}{{}}}
\bibcite{Edge}{{6}{}{{}}{{}}}
\bibcite{Lecun2015}{{7}{}{{}}{{}}}
\bibcite{Langkvist2014AModeling}{{8}{}{{}}{{}}}
\bibcite{HermansTrainingNetworks}{{9}{}{{}}{{}}}
\bibcite{Bengio1994LearningDifficult}{{10}{}{{}}{{}}}
\bibcite{ChoLearningTranslation}{{11}{}{{}}{{}}}
\bibcite{Hochreiter1997LongMemory}{{12}{}{{}}{{}}}
\bibcite{Ester1996A}{{13}{}{{}}{{}}}
\bibcite{MalhotraLongSeries}{{14}{}{{}}{{}}}
\bibcite{TensorFlow}{{15}{}{{}}{{}}}
\bibcite{Krishnan2000}{{16}{}{{}}{{}}}
\bibcite{Hasan2014}{{17}{}{{}}{{}}}
\bibcite{Tang2017RethinkingDemands}{{18}{}{{}}{{}}}
\bibcite{Borst2010}{{19}{}{{}}{{}}}
\bibcite{Leconte2016}{{20}{}{{}}{{}}}
\bibcite{Applegate2016}{{21}{}{{}}{{}}}
\bibcite{JiangCFA:Optimization}{{22}{}{{}}{{}}}
\bibcite{Zhao2017LearningNetworks}{{23}{}{{}}{{}}}
\bibcite{Yadwadkar2017SelectingClouds}{{24}{}{{}}{{}}}
\bibcite{Schmidhuber1989}{{25}{}{{}}{{}}}
\bibcite{Qin}{{26}{}{{}}{{}}}
\bibcite{Zhu2017DeepUber}{{27}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The prediction result on test set.}}{10}{figure.12}}
\newlabel{fig:result_test_set}{{12}{10}{The prediction result on test set}{figure.12}{}}
\@LN@col{1}
\@LN@col{2}
